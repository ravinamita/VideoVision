# Define global args
ARG FUNCTION_DIR="/home/app/"
ARG RUNTIME_VERSION="3.8"
ARG DISTRO_VERSION="3.12"

FROM alpine:latest as alpine

FROM python:${RUNTIME_VERSION} AS python-alpine

RUN python${RUNTIME_VERSION} -m pip install --upgrade pip

FROM python-alpine AS build-image

# Include global args in this stage of the build
ARG FUNCTION_DIR
ARG RUNTIME_VERSION

# Create function directory
RUN mkdir -p ${FUNCTION_DIR}

# Install Lambda Runtime Interface Client for Python
RUN python${RUNTIME_VERSION} -m pip install awslambdaric --target ${FUNCTION_DIR}

# Stage 3 - final runtime image
FROM python-alpine

# Include global arg in this stage of the build
ARG FUNCTION_DIR
# Set working directory to function root directory
WORKDIR ${FUNCTION_DIR}

# Copy in the built dependencies
COPY --from=build-image ${FUNCTION_DIR} ${FUNCTION_DIR}

# (Optional) Add Lambda Runtime Interface Emulator and use a script in the ENTRYPOINT for simpler local runs
ADD https://github.com/aws/aws-lambda-runtime-interface-emulator/releases/latest/download/aws-lambda-rie /usr/bin/aws-lambda-rie

RUN chmod 755 /usr/bin/aws-lambda-rie

# Install PyTorch and Torchvision for CPU (without CUDA)
RUN pip install torch torchvision --index-url https://download.pytorch.org/whl/cpu

# Copy handler function
COPY requirements.txt ${FUNCTION_DIR}

RUN pip install -r requirements.txt --target ${FUNCTION_DIR}

COPY entry.sh /

RUN echo "cpuinfo will not work in Docker" > /etc/cpuinfo

# Create a writable directory
RUN mkdir -p /home/app/

# Copy function code
COPY face_recognition_code.py ${FUNCTION_DIR}
COPY handler.py ${FUNCTION_DIR}

RUN chmod 777 /entry.sh

# Set the CMD to your handler (could also be done as a parameter override outside of the Dockerfile)
ENTRYPOINT [ "/entry.sh" ]
CMD [ "handler.handler" ]